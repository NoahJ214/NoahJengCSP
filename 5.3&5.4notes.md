{% include navbar.html %}

## 5.3 and 5.4 Notes

-Explain how bias exists in computing innovations
* Reflect human biases b/c bias written into algorithms and data
* Programmers should try to actively reduce bias
* Bias is embedded at all levels of software

-Examples
-Netflix
-Explicit Data
1. Thumbs up/down
2. Name address etc
-Implicit
1. When you watch
2. What you binge
3. Style of shows watched

-Biases
* Exclusives featured first
* Subscriptions
* Can be intentional


Kaggle:
* Courses in visualizations, TensorFlow, AI, machine learning
* Competitions
* Notebooks
Distributed Computing:
* Donate spare computing power to help calculations
Spotify:
* Collaborative playlists
* Algorithm
* Metadata write in
Crowdfunding:
* Kickstarter
* IndieGoGo
* BlockChain

# Github Pages Actions
5.3:
* I don't think that the people at HP intentionally developed the software with racist intentions. This is because it is very easy to make mistakes when it comes to developing software, especially something as complicated as a facial recognition system. They may have not tested the software with someone with very dark skin. In order to produce a better outcome, they need to test the program with a larger sample of people, and make sure it works for all types of people, not just a small group of people who may have lots in common.

5.4:
* One crowdsourcing idea that can be implemented would be for everyone to learn a new instrument. This would eliminate all biases, since there is less bias towards specific instruments as opposed to something computer science related.
* Del Norte crowdsourcing would give us a very large sample size, with people of all different backgrounds and interests. It could improve my final project because we can get data from all around the school from many different people, giving us an accurate representation of the school's interests and opinions.